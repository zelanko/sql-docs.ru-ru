---
title: Краткое руководство по развертыванию
titleSuffix: SQL Server 2019 big data clusters
description: Пошаговое руководство по развертыванию кластеров SQL Server 2019 больших данных (Предварительная версия) в службе Azure Kubernetes (AKS).
author: rothja
ms.author: jroth
manager: craigg
ms.date: 12/17/2018
ms.topic: quickstart
ms.prod: sql
ms.technology: big-data-cluster
ms.custom: seodec18
ms.openlocfilehash: 3495d41028f72093b58f546d3da2139ff02b848d
ms.sourcegitcommit: 299b63e04498eba22659970cd077f247c1657931
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/24/2019
ms.locfileid: "54898989"
---
# <a name="quickstart-deploy-sql-server-big-data-cluster-on-azure-kubernetes-service-aks"></a>Краткое руководство. Развертывание кластера больших данных SQL Server в службе Azure Kubernetes (AKS)

В этом кратком руководстве используется пример сценария развертывания для развертывания кластера SQL Server 2019 больших данных (Предварительная версия) для службы Azure Kubernetes (AKS). 

> [!TIP]
> Только один вариант для размещения Kubernetes для больших данных кластера AKS. Дополнительные сведения о других вариантах развертывания, как для настройки развертывания параметры, см. в разделе [развертывание больших данных в SQL Server кластеров Kubernetes](deployment-guidance.md).

Развертывание кластера больших данных по умолчанию, используемый здесь состоит из экземпляра SQL Master, один вычислительный экземпляр пула, два экземпляра пула данных и два экземпляра пула хранения. Данные сохраняются с помощью постоянных томах Kubernetes, использующих классы хранения по умолчанию AKS. Конфигурация по умолчанию, в этом кратком руководстве подходит для сред разработки и тестирования.

[!INCLUDE [Limited public preview note](../includes/big-data-cluster-preview-note.md)]

## <a name="prerequisites"></a>предварительные требования

- Подписка Azure.
- [Средства работы с большими данными](deploy-big-data-tools.md):
   - **mssqlctl**
   - **kubectl**
   - **Azure Data Studio**
   - **Расширение SQL Server 2019**
   - **Azure CLI**

## <a name="log-in-to-your-azure-account"></a>Войдите в учетную запись Azure

Сценарий использует Azure CLI для автоматизации создания кластера AKS. Перед выполнением скрипта, необходимо войти в учетную запись Azure с помощью Azure CLI по крайней мере один раз. Выполните следующую команду из командной строки.

```
az login
```

## <a name="download-the-deployment-script"></a>Скачайте сценарий развертывания

В этом кратком руководстве, позволяет автоматизировать создание кластера больших данных в AKS с помощью скрипта python **развертывание — sql больших data-aks.py**. Если вы уже установили python для **mssqlctl**, вы должны иметь возможность успешного выполнения скрипта в этом кратком руководстве. 

В строке bash, PowerShell, Windows или Linux выполните следующую команду, чтобы скачать скрипт развертывания из репозитория GitHub.

```
curl -o deploy-sql-big-data-aks.py "https://raw.githubusercontent.com/Microsoft/sql-server-samples/master/samples/features/sql-big-data-cluster/deployment/aks/deploy-sql-big-data-aks.py"
```

## <a name="run-the-deployment-script"></a>Запуск скрипта развертывания

Следуйте инструкциям ниже для запуска скрипта развертывания. Этот сценарий будет создание службы AKS в Azure и затем развернуть кластер SQL Server 2019 больших данных в AKS. Можно также изменить сценарий с другими [переменные среды](deployment-guidance.md#env) для создания пользовательского развертывания.

1. Запустите сценарий с помощью следующей команды:

   ```
   python deploy-sql-big-data-aks.py
   ```

   > [!NOTE]
   > При наличии python3 и python2 на клиентском компьютере, а также в пути, вам нужно выполнить команду с помощью python3: `python3 deploy-sql-big-data-aks.py`.

1. При запросе введите следующие сведения:

   | Значение | Описание |
   |---|---|
   | **Идентификатор подписки Azure** | Идентификатор подписки Azure, используемый для AKS. Можно вывести список ваших подписок и их идентификаторы, выполнив `az account list` в другой командной строке. |
   | **Группа ресурсов Azure** | Имя группы ресурсов Azure для создания в кластере AKS. |
   | **Имя пользователя docker** | Имя пользователя Docker, предоставленные вам в рамках ограниченной общедоступной предварительной версии. |
   | **Пароль docker** | Пароль Docker, предоставленные вам в рамках ограниченной общедоступной предварительной версии. |
   | **Регион Azure** | Регион Azure для нового кластера AKS (по умолчанию **westus**). |
   | **Размер машины** | [Размер машины](https://docs.microsoft.com/azure/virtual-machines/windows/sizes) для узлов в кластере AKS (по умолчанию **Standard_L4s**). |
   | **Рабочие узлы** | Количество рабочих узлов в кластере AKS (по умолчанию **3**). |
   | **Имя кластера** | Имя кластера AKS и кластера больших данных. Имя кластера должно быть только буквенно цифровых символов нижнего регистра и без пробелов. (по умолчанию **sqlbigdata**). |
   | **Пароль** | Пароль для контроллера, HDFS/Spark шлюза и главный экземпляр (по умолчанию **MySQLBigData2019**). |
   | **Контроллер для пользователя** | Имя пользователя-контроллер (по умолчанию: **администратора**). |

   > [!IMPORTANT]
   > Значение по умолчанию **Standard_L4s** размер машины могут оказаться недоступными в каждом регионе Azure. Если выбран размер другой компьютер, убедитесь, что общее число дисков, которые могут присваиваться на узлах в кластере больше или равно 21. Каждое утверждение постоянного тома в кластере требуется подключенный диск. В настоящее время работы с большими данными кластера требуется 21 утверждения постоянного тома. Например [Standard_L4s](https://docs.microsoft.com/azure/virtual-machines/windows/sizes-storage#ls-series) размер машины, поддерживает 16 подключенные диски, поэтому три узла означает, что 48 диски могут быть подключены.

   > [!NOTE]
   > `sa` Учетная запись является системным администратором на основной экземпляр SQL Server, который создается во время установки. После создания развертывания, `MSSQL_SA_PASSWORD` переменной среды может быть обнаружен, выполнив `echo $MSSQL_SA_PASSWORD` в контейнере главного экземпляра. В целях безопасности измените вашей `sa` пароль для главного экземпляра после развертывания. Дополнительные сведения см. в разделе [Смена пароля Администратора](../linux/quickstart-install-connect-docker.md#sapassword).

1. Скрипт для начала необходимо создать кластер AKS с помощью параметров, которые вы указали. Этот этап занимает несколько минут.

   <img src="./media/quickstart-big-data-cluster-deploy/script-parameters.png" width="800px" alt="Script parameters and AKS cluster creation"/>

## <a name="monitor-the-status"></a>Мониторинг состояния

После того как сценарий создаст кластер AKS, он переходит к задать необходимые переменные среды с параметрами, указанного ранее. Затем он вызывает **mssqlctl** для развертывания кластера больших данных в AKS.

Командное окно клиента будет выводить состояние развертывания. Во время развертывания вы увидите ряд сообщений где ожидает pod контроллера:

```output
2018-11-15 15:42:02.0209 UTC | INFO | Waiting for controller pod to be up...
```

Через 10 – 20 минут вы должны быть уведомлены выполняющийся модуль контроллера:

```output
2018-11-15 15:50:50.0300 UTC | INFO | Controller pod is running.
2018-11-15 15:50:50.0585 UTC | INFO | Controller Endpoint: https://111.222.222.222:30080
```

> [!IMPORTANT]
> Всего развертывание может занять много времени из-за время, необходимое для загрузки образов контейнеров для компонентов кластера больших данных. Тем не менее он должен занять несколько часов. При возникновении проблем с развертыванием, см. в разделе [Устранение неполадок развертывания](deployment-guidance.md#troubleshoot) статьи руководство по развертыванию.

## <a name="inspect-the-cluster"></a>Проверка кластера

В любое время, во время развертывания можно использовать kubectl или портала администрирования кластера для проверки состояния и сведений о кластере работает больших данных.

### <a name="use-kubectl"></a>Используйте команду kubectl

Откройте новое окно команд для использования **kubectl** во время развертывания.

1. Выполните следующую команду, чтобы получить сводку состояния всего кластера:

   ```
   kubectl get all -n <your-cluster-name>
   ```

1. Изучение служб kubernetes и их внутренние и внешние конечные точки следующим **kubectl** команды:

   ```
   kubectl get svc -n <your-cluster-name>
   ```

1. Вы также можете проверить состояние различных POD kubernetes с помощью следующей команды:

   ```
   kubectl get pods -n <your-cluster-name>
   ```

1. Получить дополнительные сведения о конкретных pod с помощью следующей команды:

   ```
   kubectl describe pod <pod name> -n <your-cluster-name>
   ```

> [!TIP]
> Дополнительные сведения о том, как мониторинг и устранение неполадок развертывания см. в разделе [Устранение неполадок развертывания](deployment-guidance.md#troubleshoot) статьи руководство по развертыванию.

### <a name="use-the-cluster-administration-portal"></a>С помощью портала администрирования кластера

После запуска контроллера pod, также можно на портале администрирования кластера для мониторинга развертывания. Доступны на портале с помощью внешних IP-адрес и порт номер для `service-proxy-lb` (например: **https://\<ip адрес\>: 30777: портал**). Учетные данные для входа на портал соответствуют значениям для **пользователя контроллера** и **пароль** , указанный в скрипте развертывания.

Можно получить IP-адрес **службы прокси-сервера балансировки нагрузки** службу, выполнив следующую команду в окне bash или cmd:

```bash
kubectl get svc service-proxy-lb -n <your-cluster-name>
```

> [!NOTE]
> В CTP-версии 2.2 появится предупреждение о безопасности при доступе к веб-страницы, поскольку кластеры больших данных в настоящее время использует SSL-сертификатов, автоматически созданный. Кроме того в CTP-версии 2.2, он не отображается состояние master экземпляра SQL Server.

## <a name="connect-to-the-cluster"></a>Подключитесь к кластеру

После завершения скрипта развертывания, уведомляет о выходных данных успеха.

```output
2018-11-15 16:10:25.0583 UTC | INFO | Cluster state: Ready
2018-11-15 16:10:25.0583 UTC | INFO | Cluster deployed successfully.
```

Большие данные кластера SQL Server теперь развертывается в AKS. Теперь можно использовать Azure Data Studio для подключения к основной экземпляр SQL Server и конечных точек HDFS или Spark, с помощью Azure Data Studio.

### <a id="master"></a> Основной экземпляр

Основной экземпляр SQL Server — это традиционные экземпляр SQL Server, содержащий реляционных баз данных SQL Server. Следующие шаги описывают, как подключиться к основной экземпляр с помощью студии данных Azure.

1. Из командной строки найти IP-адрес главного экземпляра с помощью следующей команды:

   ```
   kubectl get svc endpoint-master-pool -n <your-cluster-name>
   ```

1. В Azure данных Studio нажмите клавишу **F1** > **новое подключение**.

1. В **тип подключения**выберите **Microsoft SQL Server**.

1. Введите IP-адрес главного экземпляра SQL Server в **имя_сервера** (например: **\<IP-адрес\>, 31433**).

1. Введите имя входа SQL **имя пользователя** (`SA`) и **пароль** (пароль, введенный в скрипте развертывания).

1. Изменить целевой объект **имя базы данных** к одному из реляционных баз данных.

   ![Подключиться к основной экземпляр](./media/quickstart-big-data-cluster-deploy/connect-to-cluster.png)

1. Нажмите клавишу **Connect**и **панель мониторинга сервера** должен отображаться.

### <a id="hdfs"></a> Шлюз HDFS и Spark

**HDFS/Spark шлюза** позволяет подключать для работы с пулом носителей HDFS и для выполнения заданий Spark. Следующие шаги описывают способ подключения с помощью Azure Data Studio.

1. Из командной строки найти IP-адрес шлюза HDFS/Spark с помощью следующей команды:

   ```
   kubectl get svc service-security-lb -n <your-cluster-name>
   ```
 
1. В Azure данных Studio нажмите клавишу **F1** > **новое подключение**.

1. В **тип подключения**выберите **кластера больших данных в SQL Server**.
   
   > [!TIP]
   > Если вы не видите **кластера больших данных в SQL Server** подключения введите, убедитесь, что вы установили [расширение SQL Server 2019](../azure-data-studio/sql-server-2019-extension.md) и перезагрузка студии данных после завершения расширения Установка.

1. Введите IP-адрес кластера больших данных в **имя_сервера** (не указать порт).

1. Введите `root` для **пользователя** и укажите **пароль** к кластеру больших данных, введенные в скрипте развертывания.

   ![Подключение к шлюзу HDFS и Spark](./media/quickstart-big-data-cluster-deploy/connect-to-cluster-hdfs-spark.png)

1. Нажмите клавишу **Connect**и **панель мониторинга сервера** должен отображаться.

## <a name="clean-up"></a>Очистить

Если вы тестируете кластеров больших данных в SQL Server в Azure, следует удалить кластер AKS, после завершения, чтобы избежать непредвиденных расходов. Не удаляйте кластер, если вы планируете продолжить использовать его.

> [!WARNING]
> Следующие шаги разрушает кластера AKS, который удаляет большие данные кластера SQL Server. Если у вас есть баз данных или данные HDFS, которые вы хотите сохранить, резервную копию данных перед удалением кластера.

Выполните следующую команду Azure CLI для удаления кластера больших данных и службы AKS в Azure (Замените `<resource group name>` с **группы ресурсов Azure** вы указали в скрипте развертывания):

```azurecli
az group delete -n <resource group name>
```

## <a name="next-steps"></a>Следующие шаги

Скрипт развертывания, настройки службы Azure Kubernetes и также развернули кластер SQL Server 2019 больших данных. Можно также настроить будущих развертываний в случаях ручной установки. Чтобы узнать больше о том, как большие данные кластеры развертываются а также способы настройки развертываний, см. в разделе [развертывание больших данных в SQL Server кластеров Kubernetes](deployment-guidance.md).

Теперь, когда развертывания кластера больших данных SQL Server можно загрузить демонстрационные данные и изучение учебников по:

> [!div class="nextstepaction"]
> [Учебник. Загрузка образца данных в кластере SQL Server 2019 больших данных](tutorial-load-sample-data.md)