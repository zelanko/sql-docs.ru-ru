---
title: Настройка производительности — результаты
description: В этой статье приводятся сводные данные по методам, обобщаются результаты и даются заключения по двум примерам использования, в которых тестировались различные способы оптимизации.
ms.prod: sql
ms.technology: machine-learning
ms.date: 03/29/2019
ms.topic: conceptual
author: dphansen
ms.author: davidph
ms.custom: seo-lt-2019
monikerRange: '>=sql-server-2016||>=sql-server-linux-ver15||=sqlallproducts-allversions'
ms.openlocfilehash: 068b7aa3c068b10b787b99bba26c12a2b680bcd3
ms.sourcegitcommit: ff82f3260ff79ed860a7a58f54ff7f0594851e6b
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/29/2020
ms.locfileid: "73727406"
---
# <a name="performance-for-r-services-results-and-resources"></a>Производительность служб R Services: результаты и ресурсы
[!INCLUDE[appliesto-ss-xxxx-xxxx-xxx-md](../../includes/appliesto-ss-xxxx-xxxx-xxx-md.md)]

Эта статья является четвертой и последней в серии статьей. В ней описывается оптимизация производительности для служб R Services. В этой статье приводятся сводные данные по методам, обобщаются результаты и даются заключения по двум примерам использования, в которых тестировались различные способы оптимизации.

Каждый пример преследовал собственную цель.

+ В первом примере использования команда разработчиков служб R Services пыталась дать количественную оценку влияния конкретных методов оптимизации.
+ Во втором примере команда специалистов по обработке и анализу данных экспериментировала с несколькими методами для определения наилучшей оптимизации для конкретного сценария оценки больших объемов данных.

В этом разделе приводятся подробные результаты по первому примеру использования. Для второго примера доступна сводка с общими выводами. В конце этого раздела находятся ссылки на все скрипты и образцы данных, а также на ресурсы, с которыми работали первые авторы.

## <a name="performance-case-study-airline-dataset"></a>Пример производительности: набор данных по авиарейсам

В этом примере использования команда разработчиков служб SQL Server R Services проверила влияние различных оптимизаций. Была создана модель rxLogit и выполнена оценка на основе набора данных по авиарейсам. Для оценки отдельных моментов во время процессов обучения и оценки применялись оптимизации.

- GitHub: [образцы данных и скриптов](https://github.com/Microsoft/SQL-Server-R-Services-Samples/tree/master/PerfTuning) для исследования оптимизаций SQL Server

### <a name="test-methods"></a>Методы теста

1. Набор данных по авиарейсам состоит из одной таблицы, содержащей 10 миллионов строк. Она была скачана и в ходе операции массовой загрузки отправлена на SQL Server.
2. Было сделано шесть копий таблицы.
3. В копии таблицы были внесены различные изменения для тестирования таких функций SQL Server, как сжатие страниц, сжатие строк, индексирование, хранение данных в столбцах и т. д.
4. Производительность измерялась до и после применения каждой оптимизации.

| Имя таблицы| Описание|
|------|------|
| *airline* | Данные, преобразованные из исходного XDF-файла с использованием `rxDataStep`.|                          |
| *airlineWithIntCol*   | Параметр *DayOfWeek*, преобразованный в целое число, а не в строку. Эта таблица также добавляет столбец *rowNum*.|
| *airlineWithIndex*    | Здесь содержатся те же данные, что и в таблице *airlineWithIntCol*, но с одним кластеризованным индексом с применением столбца *rowNum*.|
| *airlineWithPageComp* | Здесь содержатся те же данные, что и в таблице *airlineWithIndex*, но с включенным сжатием страниц. Эта таблица также добавляет два столбца, *CRSDepHour* и *Late*, которые вычисляются из параметров *CRSDepTime* и *ArrDelay*. |
| *airlineWithRowComp*  | Здесь содержатся те же данные, что и в таблице *airlineWithIndex*, но с включенным сжатием строк. Эта таблица также добавляет два столбца, *CRSDepHour* и *Late*, которые вычисляются из параметров *CRSDepTime* и *ArrDelay*. |
| *airlineColumnar*     | Хранилище столбцов с одним кластеризованным индексом. Эта таблица заполняется данными из очищенного CSV-файла.|

Каждый тест состоял из следующих шагов.

1. Перед выполнением каждого теста вызывалась сборка мусора R.
2. На основе данных таблицы была создана модель логистической регрессии. Для параметра *rowsPerRead* каждого теста было задано значение 500 000.
3. Для создания оценок использовалась обученная модель.
4. Каждый тест выполнялся шесть раз. Данные о времени первого запуска ("холодный запуск") были удалены. Чтобы разрешить случайные выбросы, данные о **максимальном** времени оставшихся пяти выполнений также были удалены. На основе среднего значения продолжительности четырех оставшихся выполнений вычислено среднее значение времени, затраченного на выполнение каждого теста.
5. Тесты выполнялись с использованием параметра *reportProgress* со значением 3 (время отчета и ход выполнения). Каждый выходной файл содержит сведения о времени выполнения операций ввода-вывода, времени перехода и вычисления. Эти значения полезны для устранения неполадок и диагностики.
6. Выходные данные консоли были переданы в файл в выходном каталоге.
7. Тестовые скрипты обработали время в этих файлах для вычисления среднего времени выполнения.

Например, ниже приведены значения времени из одного теста. Нам нужны значения **общего времени чтения** (время ввода-вывода) и **времени перехода** (дополнительное время на настройку процессов для вычисления).

**Примеры значений времени**

```text
Running IntCol Test. Using airlineWithIntCol table.
run 1 took 3.66 seconds
run 2 took 3.44 seconds
run 3 took 3.44 seconds
run 4 took 3.44 seconds
run 5 took 3.45 seconds
run 6 took 3.75 seconds
  
Average Time: 3.4425
metric time pct
1 Total time 3.4425 100.00
2 Overall compute time 2.8512 82.82
3 Total read time 2.5378 73.72
4 Transition time 0.5913 17.18
5 Total non IO time 0.3134 9.10
```

Рекомендуется скачать и изменить скрипты тестирования, чтобы в дальнейшем получать помощь в устранении неполадок, связанных со службами R Services или функциями RevoScaleR.

### <a name="test-results-all"></a>Результаты тестов (все)

В этом разделе сравниваются результаты, полученные до и после выполнения каждого теста.

#### <a name="data-size-with-compression-and-a-columnar-table-store"></a>Размер данных с сжатием и хранилище таблицы столбцов

В первом тесте сравнивалось применение сжатия и таблицы столбцов для уменьшения объема данных.

| Имя таблицы            | Строки     | Reserved   | Данные       | index_size | Не используется  | Процент сохранения (зарезервировано) |
|-----------------------|----------|------------|------------|------------|---------|---------------------|
| *airlineWithIndex*    | 10 000 000 | 2 978 816 КБ | 2 972 160 КБ | 6128 КБ    | 528 КБ  | 0                   |
| *airlineWithPageComp* | 10 000 000 | 625 784 КБ  | 623 744 КБ  | 1352 КБ    | 688 КБ  | 79 %                 |
| *airlineWithRowComp*  | 10 000 000 | 1 262 520 КБ | 1 258 880 КБ | 2552 КБ    | 1088 КБ | 58 %                 |
| *airlineColumnar*     | 9 999 999  | 201 992 КБ  | 201 624 КБ  | Недоступно        | 368 КБ  | 93 %                 |

**Заключения**

Максимальное сокращение размера данных было достигнуто за счет применения индекса columnstore, после которого выполнялось сжатие страницы.

#### <a name="effects-of-compression"></a>Влияние сжатия

В этом тесте сравнивались преимущества сжатия строк, сжатия страниц и отсутствия сжатия. Модель была обучена с помощью `rxLinMod` на основе данных из трех разных таблиц. Для всех таблиц использованы те же формулы и запросы.

| Имя таблицы            | Имя теста       | numTasks | Среднее время |
|-----------------------|-----------------|----------|--------------|
| *airlineWithIndex*    | NoCompression   | 1        | 5,6775       |
|                       | NoCompression — parallel| 4        | 5,1775       |
| *airlineWithPageComp* | PageCompression | 1        | 6,7875       |
|                       | PageCompression — parallel | 4        | 5,3225       |
| *airlineWithRowComp*  | RowCompression  | 1        | 6,1325       |
|                       | RowCompression — parallel  | 4        | 5,2375       |

**Заключения**

По всей видимости, одно лишь сжатие не эффективно. В этом примере увеличение ресурсов ЦП для обработки сжатия компенсирует сокращение времени ввода-вывода.

Однако при выполнении теста в параллельном режиме (для параметра *numTasks* задано значение 4) значение среднего времени сокращается.

Для более крупных наборов данных влияние сжатия может быть более заметным. Сжатие зависит от набора данных и значений. Поэтому, чтобы определить, как сжатие влияет на ваш набор данных, нужно поэкспериментировать.

### <a name="effect-of-windows-power-plan-options"></a>Влияние вариантов схемы электропитания Windows

В этом эксперименте параметр `rxLinMod` использовался с таблицей *airlineWithIntCol*. Для схемы электропитания Windows были заданы значения **Сбалансированная** или **С высокой производительностью**. Для всех тестов для параметра *numTasks* было задано значение 1. Тест выполнялся шесть раз и дважды с включением обоих параметров электропитания, чтобы показать и изучить разброс результатов.

Вариант электропитания **С высокой производительностью**

| Имя теста | Выполнить \# | Истекшее время | Среднее время |
|-----------|--------|--------------|--------------|
| IntCol    | 1      | 3,57 с |              |
|           | 2      | 3,45 с |              |
|           | 3      | 3,45 с |              |
|           | 4      | 3,55 с |              |
|           | 5      | 3,55 с |              |
|           | 6      | 3,45 с |              |
|           |        |              | 3.475        |
|           | 1      | 3,45 с |              |
|           | 2      | 3,53 с |              |
|           | 3      | 3,63 с |              |
|           | 4      | 3,49 с |              |
|           | 5      | 3,54 с |              |
|           | 6      | 3,47 с |              |
|           |        |              | 3,5075       |

Вариант **сбалансированного** электропитания:

| Имя теста | Выполнить \# | Истекшее время | Среднее время |
|-----------|--------|--------------|--------------|
| IntCol    | 1      | 3,89 с |              |
|           | 2      | 4,15 с |              |
|           | 3      | 3,77 с |              |
|           | 4      | 5 с    |              |
|           | 5      | 3,92 с |              |
|           | 6      | 3,8 с  |              |
|           |        |              | 3,91         |
|           | 1      | 3,82 с |              |
|           | 2      | 3,84 с |              |
|           | 3      | 3,86 с |              |
|           | 4      | 4,07 с |              |
|           | 5      | 4,86 с |              |
|           | 6      | 3,75 с |              |
|           |        |              | 3,88         |

**Заключения**

Показатели времени выполнения более согласованные и низкие при использовании схемы электропитания Windows **С высокой производительностью**.

#### <a name="using-integer-vs-strings-in-formulas"></a>Использование целых чисел и строк в формулах

В ходе этого теста оценивалось влияние изменения кода R для устранения распространенной проблемы со строковыми коэффициентами. В частности, модель была обучена с помощью `rxLinMod` с использованием двух таблиц: в первой таблице коэффициенты хранятся в виде строк, во второй таблице — в виде целых чисел.

+ В таблице *airline* столбец [DayOfWeek] содержит строки. Использовался параметр _colInfo_, чтобы указать уровень коэффициента (понедельник, вторник и т. д.).

+  В таблице *airlineWithIndex* значение [DayOfWeek] является целым числом. Параметр _colInfo_ не был задан.

+ В обоих случаях использовалась одна формула: `ArrDelay ~ CRSDepTime + DayOfWeek`.

| Имя таблицы          | Имя теста   | Среднее время |
|---------------------|-------------|--------------|
| *Airline*           | *FactorCol* | 10,72        |
| *airlineWithIntCol* | *IntCol*    | 3,4475       |

**Заключения**

Использование целых чисел вместо строк является очевидным преимуществом.

### <a name="avoiding-transformation-functions"></a>Выполнение теста без функций преобразования

В этом тесте модель была обучена с помощью `rxLinMod`, но между двумя запусками в код были внесены изменения.

+ В первом запуске в процессе создания модели была применена функция преобразования. 
+ Во втором запуске были предварительно вычислены и доступны значения компонентов, поэтому функция преобразования не требовалась.

| Имя теста             | Среднее время |
|-----------------------|--------------|
| WithTransformation    | 5,1675       |
| WithoutTransformation | 4,7          |

**Заключения**

Время обучения было короче **без** применения функции преобразования. Иными словами, обучение модели прошло быстрее при использовании столбцов, предварительно вычисленных и сохраненных в таблице.

Это значение было бы еще ниже, если бы имелось больше преобразований и набор данных был крупнее (\> 100 млн строк).

### <a name="using-columnar-store"></a>Использование хранилища столбцов

В этом тесте оценивались преимущества производительности при использовании хранилища столбцов и индекса столбца. Та же модель была обучена с помощью `rxLinMod` без преобразований данных.

+ В первом запуске таблица данных использовала стандартное хранилище строк.
+ Во втором запуске использовалось хранилище столбцов.

| Имя таблицы         | Имя теста | Среднее время |
|--------------------|-----------|--------------|
| *airlineWithIndex* | RowStore  | 4,67         |
| *airlineColumnar*  | ColStore  | 4,555        |

**Заключения**

Более высокая производительность была достигнута при использовании хранилища столбцов. Значительную разницу в производительности можно ожидать при работе с крупными наборами данных (\> 100 млн строк).

### <a name="effect-of-using-the-cube-parameter"></a>Влияние использования параметра куба

Цель этого теста — определить возможность повышения производительности с помощью предварительно вычисленного параметра **cube** в RevoScaleR. Модель была обучена с помощью `rxLinMod` по следующей формуле:

```R
ArrDelay ~ Origin:DayOfWeek + Month + DayofMonth + CRSDepTime
```

В таблице коэффициенты *DayOfWeek* хранятся в виде строки.

| Имя теста     | Параметр куба | numTasks | Среднее время | Прогнозирование одной строки (ArrDelay_Pred) |
|---------------|----------------|----------|--------------|---------------------------------|
| CubeArgEffect | `cube = F`     | 1        | 91,0725      | 9,959204                        |
|               |                | 4        | 44,09        | 9,959204                        |
|               | `cube = T`     | 1        | 21,1125      | 9,959204                        |
|               |                | 4        | 8.08         | 9,959204                        |

**Заключения**

Использование аргумента параметра куба, безусловно, повышает производительность.

### <a name="effect-of-changing-maxdepth-for-rxdtree-models"></a>Влияние изменения maxDepth для моделей rxDTree

В этом эксперименте для создания модели в таблице *airlineColumnar* использовался алгоритм `rxDTree`. Для этого теста для параметра *numTasks* задано значение 4. Использовались несколько разных значений *maxDepth*, чтобы показать, как изменение глубины дерева влияет на время выполнения.

| Имя теста       | maxDepth | Среднее время |
|-----------------|----------|--------------|
| TreeDepthEffect | 1        | 10,1975      |
|                 | 2        | 13,2575      |
|                 | 4        | 19,27        |
|                 | 8        | 45,5775      |
|                 | 16       | 339,54       |

**Заключения**

По мере увеличения глубины дерева общее число узлов растет экспоненциально. Также значительно увеличилось время, затраченное на создание модели.

### <a name="prediction-on-a-stored-model"></a>Прогнозирование с помощью хранимой модели

Цель этого теста — определить влияние производительности на оценку при сохранении обученной модели в таблицу SQL Server, а не при создании в виде фрагмента выполняемого в данный момент кода. Для выполнения оценки хранимая модель загружается из базы данных и создаются прогнозы с использованием кадра данных с одной строкой в памяти (локальный контекст вычисления).

В результатах теста показано время сохранения и загрузки модели, а также время прогнозирования.

| Имя таблицы | Имя теста | Среднее время (для обучения модели) | Время сохранения и загрузки модели|
|------------|------------|------------|------------|
| авиакомпания    | SaveModel| 21,59| 2,08|
| авиакомпания    | LoadModelAndPredict | | 2,09 (со временем для прогнозирования) |

**Заключения**

Загрузка обученной модели из таблицы однозначно является более быстрым способом прогнозирования. Создавать модель и выполнять оценку в одном скрипте не рекомендуется.

## <a name="case-study-optimization-for-the-resume-matching-task"></a>Пример использования: оптимизация задачи отбора подходящих резюме

Специалист корпорации Майкрософт по обработке и анализу данных Ке Хуанг (Ke Huang) разработал модель отбора подходящих резюме для тестирования производительности кода R в SQL Server, чтобы специалисты по обработке и анализу данных могли создавать масштабируемые решения корпоративного уровня.

### <a name="methods"></a>Методы

Для обучения прогнозной модели в сложном решении R с большими наборами данных использовались пакеты RevoScaleR и MicrosoftML. Запросы SQL и код R были идентичны во всех тестах. Тесты проводились на одной виртуальной машине Azure с установленными SQL Server. Затем автор сравнил время оценки со следующими оптимизациями, предоставляемыми SQL Server, и без них:

- Таблицы в памяти
- Soft-NUMA
- Resource Governor

Чтобы оценить влияние программной архитектуры NUMA на выполнение скрипта R, команда специалистов по обработке и анализу данных проверила решение на виртуальной машине Azure с 20 физическими ядрами. На этих физических ядрах были автоматически созданы четыре узла программной архитектуры NUMA, так что каждый узел содержал пять ядер.

Для оценки влияния на задания в сценарии отбора подходящих резюме было применено соответствие ЦП. Были созданы четыре **пула ресурсов SQL** и четыре **пула внешних ресурсов**, а также было указано соответствие ЦП, чтобы на каждом узле использовался один и тот же набор процессоров.

В целях оптимизации использования оборудования каждый пул ресурсов был назначен разной группе рабочей нагрузки. Причина в том, что программная архитектура NUMA и соответствие ЦП не могут разделять физическую память на физических узлах NUMA. Таким образом, по определению все узлы программной архитектуры NUMA, в основе которых лежит один физический узел NUMA, должны использовать память в одном блоке памяти ОС. Другими словами, между памятью и процессором нет соответствия.

Для создания этой конфигурации использовался следующий процесс.

1. Сокращение объема памяти, выделенной по умолчанию для SQL Server.

2. Создание четыре новых пулов для параллельного выполнения заданий R.

3. Создание четырех групп рабочей нагрузки и связывание каждой группы с пулом ресурсов.

4. Перезапуск Resource Governor с новыми группами рабочей нагрузки и назначениями.

5. Создание определяемой пользователем функции-классификатора (UDF) для назначения разных задач разным группам рабочей нагрузки.

6. Обновление конфигурации Resource Governor для использования функции для соответствующих групп рабочей нагрузки.

### <a name="results"></a>Результаты

Лучшая производительность оказалась у конфигурации со следующими характеристиками:

-   четыре пула внутренних ресурсов (для SQL Server);

-   четыре внешних пула ресурсов (для заданий внешних скриптов);

-   каждый пул ресурсов связан с определенной группой рабочей нагрузки;

-   каждый пул ресурсов назначен разным ЦП;

-   максимальный объем использования внутренней памяти (для SQL Server) — 30 %;

-   максимальный объем памяти, используемый сеансами R, — 70 %.

Для модели отбора подходящих резюме использование внешнего скрипта было сопряжено с трудностями, и не было других запущенных служб ядра СУБД. Таким образом, объем ресурсов, выделенных для внешних скриптов, был увеличен до 70 %, и в результате была сформирована оптимальная конфигурация для производительности скриптов.

Эта конфигурация была получена в ходе экспериментов с различными значениями. Если вы используете другое оборудование или другое решение, оптимальная конфигурация может отличаться от приведенной выше. Всегда экспериментируйте, чтобы найти подходящую конфигурацию для каждого конкретного случая.

В оптимизированном решении 1 100 000 строк данных (с сотней функций) прошли оценку в течение 8,5 секунд на 20-ядерном компьютере. Оптимизации значительно повысили производительность с точки зрения времени оценки.

Кроме того, результаты показали, что на время оценки оказало серьезное влияние **число функций**. Улучшение было еще более заметным, когда в модели прогнозирования использовались дополнительные функции.

Для получения подробных сведений рекомендуется ознакомиться со следующей публикацией блога и сопутствующим руководством.

-   [Советы и рекомендации по оптимизации для машинного обучения в SQL Server](https://azure.microsoft.com/blog/optimization-tips-and-tricks-on-azure-sql-server-for-machine-learning-services/)

Многие пользователи отметили, что при первой загрузке среды выполнения R (или Python) возникает небольшая пауза. По этой причине, как описано в этих тестах, время первого запуска часто измеряется, но позже не учитывается. Последующее кэширование может привести к существенным различиям в производительности между первым и вторым запусками. Кроме того, при перемещении данных между SQL Server и внешней средой выполнения также существуют некоторые издержки, которые особенно заметны при передаче данных по сети, а не при загрузке непосредственно из SQL Server.

В силу всего этого единое решение для исключения этого времени начальной загрузки отсутствует, так как влияние на производительность в значительной степени зависит от этой задачи. Например, кэширование для оценки одной строки происходит в пакетном режиме. Следовательно, последующие операции оценки выполняются гораздо быстрее, причем перезагружать модель или среду выполнения R не требуется. Чтобы не загружать среду выполнения полностью, можно также воспользоваться функцией [собственной оценки](../sql-native-scoring.md).

При обучении больших моделей или оценки крупными частями издержки можно считать минимальными по сравнению с преимуществами потоковой передачи и параллельной обработкой или отказа от перемещения данных. Дополнительные рекомендации по повышению производительности см. в этой записи блога:

+ [Использование R для обнаружения случаев мошенничества при обработке 1 000 000 транзакций в секунду](https://blog.revolutionanalytics.com/2016/09/fraud-detection.html/)

## <a name="resources"></a>Ресурсы

Ниже приведены ссылки на материалы, инструменты и скрипты, которые использовались при разработке этих тестов.

+ Скрипты тестирования производительности и ссылки на данные: [Образцы данных и скриптов для исследования оптимизаций SQL Server](https://github.com/Microsoft/SQL-Server-R-Services-Samples/tree/master/PerfTuning)

+ Статья с описанием решения по отбору подходящих резюме: [Советы и рекомендации по оптимизации для служб SQL Server R Services](https://azure.microsoft.com/blog/optimization-tips-and-tricks-on-azure-sql-server-for-machine-learning-services/)

+ Скрипты, используемые в оптимизации SQL для решения по отбору подходящих резюме: [репозиторий GitHub](https://github.com/Microsoft/SQL-Server-R-Services-Samples/tree/master/SQLOptimizationTips)

### <a name="learn-about-windows-server-management"></a>Дополнительные сведения об управлении Windows Server

+ [Как определить размер файла подкачки для 64-разрядных версий Windows](https://support.microsoft.com/kb/2860880)

+ [Основные сведения об архитектуре NUMA](https://technet.microsoft.com/library/ms178144.aspx)

+ [Как SQL Server поддерживает архитектуру NUMA](https://technet.microsoft.com/library/ms180954.aspx)

+ [Программная архитектура NUMA](https://docs.microsoft.com/sql/database-engine/configure-windows/soft-numa-sql-server)

### <a name="learn-about-sql-server-optimizations"></a>Дополнительные сведения об оптимизациях SQL Server

+ [Реорганизация и перестроение индексов](../../relational-databases/indexes/reorganize-and-rebuild-indexes.md)

+ [Введение в таблицы, оптимизированные для памяти](https://docs.microsoft.com/sql/relational-databases/in-memory-oltp/introduction-to-memory-optimized-tables)

+ [Демонстрация. Повышение производительности In-Memory OLTP](https://docs.microsoft.com/sql/relational-databases/in-memory-oltp/demonstration-performance-improvement-of-in-memory-oltp)

+ [Сжатие данных](../../relational-databases/data-compression/data-compression.md)

+ [Включение сжатия таблицы или индекса](../../relational-databases/data-compression/enable-compression-on-a-table-or-index.md)

+ [Отключение сжатия таблицы или индекса](../../relational-databases/data-compression/disable-compression-on-a-table-or-index.md)

### <a name="learn-about-managing-sql-server"></a>Дополнительные сведения об управлении SQL Server

+ [Наблюдение и настройка производительности](../../relational-databases/performance/monitor-and-tune-for-performance.md)

+ [Регулятор ресурсов](../../relational-databases/resource-governor/resource-governor.md)

+ [Знакомство с Resource Governor](https://technet.microsoft.com/library/bb895232.aspx)

+ [Управление ресурсами для служб R](resource-governance-for-r-services.md)

+ [Практическое руководство по созданию пула ресурсов для R](how-to-create-a-resource-pool-for-r.md)

+ [Пример настройки Resource Governor](https://blog.sqlauthority.com/2012/06/04/sql-server-simple-example-to-configure-resource-governor-introduction-to-resource-governor/)

### <a name="tools"></a>Инструменты

+ [Генератор загрузки хранилища DISKSPD. Тестовое средство производительности](https://github.com/microsoft/diskspd)

+ [Fsutil](https://technet.microsoft.com/library/cc753059.aspx)


## <a name="other-articles-in-this-series"></a>Другие статьи в этой серии

[Настройка производительности для R — введение](sql-server-r-services-performance-tuning.md)

[Настройка производительности для R — конфигурация SQL Server](sql-server-configuration-r-services.md)

[Настройка производительности для R — код R и оптимизация данных](r-and-data-optimization-r-services.md)

[Настройка производительности — результаты примеров использования](performance-case-study-r-services.md)
